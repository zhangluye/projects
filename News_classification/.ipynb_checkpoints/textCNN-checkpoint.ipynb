{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===============================  data loading success! ===================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "traindata_path = './data_processed/train_data.csv'\n",
    "df_all = pd.read_csv(traindata_path, header=None, engine=\"python\", encoding=\"utf-8\")  #8597\n",
    "df_all.columns = [\"index\",\"words\",\"types\",\"caijing\",\"fangchan\",\"jiaoyu\",\"junshi\",\"keji\",\"qiche\",\"tiyu\",\"youxi\",\"yule\"]\n",
    "df_all.drop(0,inplace=True)\n",
    "df_all.drop(['index'],inplace=True,axis=1)\n",
    "df_all = df_all.sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "df_all.reset_index(drop=True)\n",
    "print(' ===============================  data loading success! ===================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用独热编码表示类别\n",
    "df_types = df_all[['types']]\n",
    "df_types = df_types.replace('caijing', 0)\n",
    "df_types = df_types.replace('fangchan', 1)\n",
    "df_types =df_types.replace('jiaoyu', 2)\n",
    "df_types =df_types.replace('junshi', 3)\n",
    "df_types =df_types.replace('keji', 4)\n",
    "df_types =df_types.replace('qiche', 5)\n",
    "df_types =df_types.replace('tiyu', 6)\n",
    "df_types =df_types.replace('youxi', 7)\n",
    "df_types =df_types.replace('yule', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import *\n",
    "\n",
    "x_series = df_all['words']\n",
    "labels = to_categorical(df_types['types'].values)\n",
    "\n",
    "#将数据集按9:1分为训练集和测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_series, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: 1137\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 500\n",
    "\n",
    "#创建一个Tokenizer对象，fit_on_texts函数可以将输入的文本中的每个词编号，编号是根据词频的，词频越大，编号越小\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_series)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# 将每个样本中的每个词转换为数字列表，使用每个词的编号进行编号\n",
    "x_train_word_ids = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_word_ids = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# 每条样本长度不唯一，将每条样本的长度设置一个固定值\n",
    "x_train_padded_seqs=pad_sequences(x_train_word_ids,maxlen) #将超过固定值的部分截掉，不足的在最前面用0填充\n",
    "x_test_padded_seqs=pad_sequences(x_test_word_ids, maxlen)\n",
    "\n",
    "print('Shape of data tensor:', len(x_train_word_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyz/anaconda3/lib/python3.6/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "# 加载bin格式的模型\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(\"./model/content_w2v.bin\", binary=True)\n",
    "\n",
    "# 预训练的词向量中没有出现的词用0向量表示，出现的词在w2v模型中找到其对应的向量\n",
    "embedding_matrix = np.zeros((len(word_index) + 1 , 100))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        embedding_vector = w2v_model[str(word)]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 2s 28ms/step - loss: 0.3846 - accuracy: 0.2427 - val_loss: 0.1482 - val_accuracy: 0.7675\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.1238 - accuracy: 0.7900 - val_loss: 0.1124 - val_accuracy: 0.8070\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.0743 - accuracy: 0.8833 - val_loss: 0.0785 - val_accuracy: 0.8772\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.0445 - accuracy: 0.9309 - val_loss: 0.0591 - val_accuracy: 0.9254\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.0293 - accuracy: 0.9673 - val_loss: 0.0947 - val_accuracy: 0.8772\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0248 - accuracy: 0.9693 - val_loss: 0.0576 - val_accuracy: 0.9167\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0148 - accuracy: 0.9859 - val_loss: 0.0595 - val_accuracy: 0.9342\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0073 - accuracy: 0.9947 - val_loss: 0.0735 - val_accuracy: 0.9386\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.0114 - accuracy: 0.9865 - val_loss: 0.0625 - val_accuracy: 0.9342\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0060 - accuracy: 0.9973 - val_loss: 0.0590 - val_accuracy: 0.9254\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0081 - accuracy: 0.9935 - val_loss: 0.0672 - val_accuracy: 0.9342\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.0779 - val_accuracy: 0.9254\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.0039 - accuracy: 0.9930 - val_loss: 0.0607 - val_accuracy: 0.9430\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0016 - accuracy: 0.9976 - val_loss: 0.0746 - val_accuracy: 0.9342\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0013 - accuracy: 0.9975 - val_loss: 0.0940 - val_accuracy: 0.9123\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.0135 - accuracy: 0.9949 - val_loss: 0.0810 - val_accuracy: 0.8991\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.0048 - accuracy: 0.9978 - val_loss: 0.0714 - val_accuracy: 0.9342\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0012 - accuracy: 0.9985 - val_loss: 0.0754 - val_accuracy: 0.9342\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 0.0767 - val_accuracy: 0.9342\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.0013 - accuracy: 0.9973 - val_loss: 0.0776 - val_accuracy: 0.9386\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.0014 - accuracy: 0.9984 - val_loss: 0.0789 - val_accuracy: 0.9386\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0010 - accuracy: 0.9976 - val_loss: 0.0795 - val_accuracy: 0.9342\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 8.9378e-04 - accuracy: 0.9987 - val_loss: 0.0816 - val_accuracy: 0.9386\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 3.4258e-04 - accuracy: 0.9998 - val_loss: 0.0834 - val_accuracy: 0.9430\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0011 - accuracy: 0.9984 - val_loss: 0.0820 - val_accuracy: 0.9430\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 5.1182e-04 - accuracy: 0.9996 - val_loss: 0.0838 - val_accuracy: 0.9386\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 8.4788e-04 - accuracy: 0.9991 - val_loss: 0.0872 - val_accuracy: 0.9430\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.0012 - accuracy: 0.9984 - val_loss: 0.0866 - val_accuracy: 0.9430\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0013 - accuracy: 0.9949 - val_loss: 0.0874 - val_accuracy: 0.9386\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 0.9963 - val_loss: 0.0897 - val_accuracy: 0.9386\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 9.7638e-04 - accuracy: 0.9983 - val_loss: 0.0905 - val_accuracy: 0.9430\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 5.1307e-04 - accuracy: 0.9991 - val_loss: 0.0901 - val_accuracy: 0.9386\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 9.1793e-04 - accuracy: 0.9984 - val_loss: 0.0884 - val_accuracy: 0.9430\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 4.7073e-04 - accuracy: 0.9993 - val_loss: 0.0917 - val_accuracy: 0.9474\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 4.7798e-04 - accuracy: 0.9992 - val_loss: 0.0939 - val_accuracy: 0.9430\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 5.0419e-04 - accuracy: 0.9982 - val_loss: 0.0924 - val_accuracy: 0.9474\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 6.3228e-04 - accuracy: 0.9994 - val_loss: 0.0940 - val_accuracy: 0.9430\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0019 - accuracy: 0.9936 - val_loss: 0.0960 - val_accuracy: 0.9430\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.3971e-04 - accuracy: 0.9998 - val_loss: 0.0975 - val_accuracy: 0.9474\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0013 - accuracy: 0.9971 - val_loss: 0.0971 - val_accuracy: 0.9518\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.0020 - accuracy: 0.9963 - val_loss: 0.0935 - val_accuracy: 0.9474\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.0024 - accuracy: 0.9946 - val_loss: 0.0980 - val_accuracy: 0.9474\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 6.6166e-04 - accuracy: 0.9979 - val_loss: 0.1011 - val_accuracy: 0.9474\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 6.8322e-04 - accuracy: 0.9975 - val_loss: 0.1049 - val_accuracy: 0.9430\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 9.3568e-04 - accuracy: 0.9962 - val_loss: 0.0997 - val_accuracy: 0.9474\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.0011 - accuracy: 0.9966 - val_loss: 0.0988 - val_accuracy: 0.9430\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 9.7820e-04 - accuracy: 0.9972 - val_loss: 0.1054 - val_accuracy: 0.9430\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0012 - accuracy: 0.9972 - val_loss: 0.1047 - val_accuracy: 0.9430\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0016 - accuracy: 0.9941 - val_loss: 0.1023 - val_accuracy: 0.9474\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0015 - accuracy: 0.9958 - val_loss: 0.1044 - val_accuracy: 0.9474\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input,Embedding,Conv1D,MaxPooling1D,Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization,Dense,Dropout,Lambda\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "#搭建网络\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                           100,\n",
    "                           weights = [embedding_matrix],\n",
    "                           input_length = maxlen,\n",
    "                           trainable = False))\n",
    "model.add(Conv1D(128, 3, padding='same',strides=1, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(128, 4, padding='same', strides=1, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(128, 5, padding='same', strides=1, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(x_train_padded_seqs, y_train, epochs=50, batch_size=20,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算f1、precision、recall\n",
    "def return_f1(y_predict,y_test):\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1=[]\n",
    "    for label in range(y_predict.shape[1]):\n",
    "        tp=0\n",
    "        fp=0\n",
    "        tn=0\n",
    "        fn=0\n",
    "        for i in range(len(y_test)):\n",
    "            if np.argmax(y_test[i])==label:\n",
    "                if (np.argmax(y_test[i]))==(np.argmax(y_predict[i])):\n",
    "                    tp+=1\n",
    "                else:\n",
    "                    fn+=1\n",
    "            else:\n",
    "                if (np.argmax(y_predict[i]))!=label:\n",
    "                    tn+=1\n",
    "                else:\n",
    "                    fp+=1\n",
    "        precision=tp/(tp+fp)\n",
    "        recall=tp/(tp+fn)\n",
    "        \n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        \n",
    "        f1.append(2*precision*recall/(precision+recall))\n",
    "    return precision_list,recall_list,f1\n",
    "        \n",
    "def get_avg(list1):\n",
    "    avg = 0\n",
    "    for i in range(len(list1)):\n",
    "        avg += list1[i]\n",
    "    return avg/len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average_precision: 0.9487342166615432\n",
      "Average_recall: 0.9556012418361731\n",
      "Average_f1: 0.9512916187877243\n"
     ]
    }
   ],
   "source": [
    "#对测试集进行预测\n",
    "y_predict =  model.predict(x_test_padded_seqs)\n",
    "\n",
    "#生成每个类别的precision、recall、f1\n",
    "precision_list,recall_list,f1_list = return_f1(y_predict,y_test)\n",
    "print('Average_precision:',get_avg(precision_list))\n",
    "print('Average_recall:',get_avg(recall_list))\n",
    "print('Average_f1:',get_avg(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        model name: TextCNN\n",
      "     precision   recall   f1-score\n",
      "财经:   0.914     0.780     0.842\n",
      "房产:   0.933     0.966     0.949\n",
      "教育:   0.952     1.000     0.976\n",
      "军事:   0.949     1.000     0.974\n",
      "科技:   0.889     0.889     0.889\n",
      "汽车:   0.966     0.966     0.966\n",
      "体育:   1.000     1.000     1.000\n",
      "游戏:   1.000     1.000     1.000\n",
      "娱乐:   0.935     1.000     0.967\n",
      "平均值: 0.949     0.956     0.951\n"
     ]
    }
   ],
   "source": [
    "print('        model name: TextCNN')\n",
    "print('     precision   recall   f1-score')\n",
    "print('财经:   %.3f'%precision_list[0],'    %.3f'%recall_list[0],'    %.3f'%f1_list[0])\n",
    "print('房产:   %.3f'%precision_list[1],'    %.3f'%recall_list[1],'    %.3f'%f1_list[1])\n",
    "print('教育:   %.3f'%precision_list[2],'    %.3f'%recall_list[2],'    %.3f'%f1_list[2])\n",
    "print('军事:   %.3f'%precision_list[3],'    %.3f'%recall_list[3],'    %.3f'%f1_list[3])\n",
    "print('科技:   %.3f'%precision_list[4],'    %.3f'%recall_list[4],'    %.3f'%f1_list[4])\n",
    "print('汽车:   %.3f'%precision_list[5],'    %.3f'%recall_list[5],'    %.3f'%f1_list[5])\n",
    "print('体育:   %.3f'%precision_list[6],'    %.3f'%recall_list[6],'    %.3f'%f1_list[6])\n",
    "print('游戏:   %.3f'%precision_list[7],'    %.3f'%recall_list[7],'    %.3f'%f1_list[7])\n",
    "print('娱乐:   %.3f'%precision_list[8],'    %.3f'%recall_list[8],'    %.3f'%f1_list[8])\n",
    "print('平均值: %.3f'%get_avg(precision_list),'    %.3f'%get_avg(recall_list),'    %.3f'%get_avg(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
